{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import kutils\n",
    "from kutils import model_helper as mh\n",
    "from kutils import applications as apps\n",
    "from kutils import tensor_ops as ops\n",
    "from kutils import generic as gen\n",
    "\n",
    "# ops.GPUMemoryCap(fraction=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "root_path = '/mnt/home/research/ava-mlsp/'\n",
    "dataset = root_path + 'metadata/AVA_data_official_test.csv';\n",
    "ids = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on narrow MLSP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = root_path + 'features/irnv2_mlsp_narrow_orig/i1[orig]_lfinal_o1[16928]_r1.h5'\n",
    "\n",
    "fc1_size = 2048\n",
    "image_size = '[orig]'\n",
    "input_size = 16928\n",
    "model_name = features_file.split('/')[-2]\n",
    "\n",
    "loss = 'MSE'\n",
    "bn = 2\n",
    "fc_sizes = [fc1_size, fc1_size/2, fc1_size/8,  1]\n",
    "dropout_rates = [0.25, 0.25, 0.5, 0]\n",
    "\n",
    "monitor_metric = 'val_loss'; monitor_mode = 'min'\n",
    "metrics = [\"MAE\", ops.plcc_tf]\n",
    "outputs = 'MOS'\n",
    "\n",
    "# MODEL DEF\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "input_feats = Input(shape=(input_size,), dtype='float32')\n",
    "\n",
    "pred = apps.fc_layers(input_feats, \n",
    "                 name          = 'head',\n",
    "                 fc_sizes      = fc_sizes, \n",
    "                 dropout_rates = dropout_rates,\n",
    "                 batch_norm    = bn)\n",
    "\n",
    "model = Model(inputs=input_feats, outputs=pred)\n",
    "\n",
    "gen_params = dict(batch_size    = 128,\n",
    "                  data_path     = features_file,\n",
    "                  input_shape   = (input_size,),\n",
    "                  inputs        = 'image_name',\n",
    "                  outputs       = outputs,\n",
    "                  random_group  = False,\n",
    "                  fixed_batches = True)\n",
    "\n",
    "helper = mh.ModelHelper(model, model_name, ids, \n",
    "                     max_queue_size = 128,\n",
    "                     loss           = loss,\n",
    "                     metrics        = metrics,\n",
    "                     monitor_metric = monitor_metric, \n",
    "                     monitor_mode   = monitor_mode,\n",
    "                     early_stop_patience = 5,\n",
    "                     multiproc      = True, workers = 3,\n",
    "                     logs_root      = root_path + 'logs',\n",
    "                     models_root    = root_path + 'models',\n",
    "                     gen_params     = gen_params)\n",
    "\n",
    "helper.model_name.update(fc1='[%d]'%fc1_size, \n",
    "                         im = image_size,\n",
    "                         bn = bn,\n",
    "                         do = str(dropout_rates).replace(' ',''),\n",
    "                         mon = '[%s]' % monitor_metric,\n",
    "                         ds = '[%s]' % os.path.split(dataset)[1])\n",
    "\n",
    "print helper.model_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# validate all at once\n",
    "valid_set = ids[ids.set == 'validation']\n",
    "valid_gen = helper.make_generator(valid_set,\n",
    "                                  batch_size    = len(valid_set),\n",
    "                                  shuffle       = False,\n",
    "                                  deterministic = False)\n",
    "\n",
    "for lr in [1e-3,1e-4,1e-5]:\n",
    "    helper.load_model()\n",
    "    helper.train(lr=lr, epochs=20, valid_gen=valid_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = root_path + 'models/irnv2_mlsp_narrow_orig/model'\n",
    "# uncomment the following line to use the trained model (default)\n",
    "# model_name = ''\n",
    "if helper.load_model(model_name=model_name):\n",
    "    y_test, y_pred, SRCC_test, PLCC_test, ACC_test =\\\n",
    "            apps.test_rating_model(helper, accuracy_thresh=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
